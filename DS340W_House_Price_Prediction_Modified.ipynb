{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b198e7c1",
      "metadata": {
        "id": "b198e7c1",
        "outputId": "8d2c2b75-f937-405a-a67c-689803f146e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flaml[notebook]==1.0.10 in /usr/local/lib/python3.7/dist-packages (1.0.10)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.0.2)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (0.90)\n",
            "Requirement already satisfied: lightgbm>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (3.3.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.7.3)\n",
            "Requirement already satisfied: rgf-python in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (3.12.0)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.0.0)\n",
            "Requirement already satisfied: openml==0.10.2 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (0.10.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (3.2.2)\n",
            "Requirement already satisfied: catboost>=0.26 in /usr/local/lib/python3.7/dist-packages (from flaml[notebook]==1.0.10) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.23.0)\n",
            "Requirement already satisfied: liac-arff>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.5.0)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (0.13.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from openml==0.10.2->flaml[notebook]==1.0.10) (2.8.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.26->flaml[notebook]==1.0.10) (1.15.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->flaml[notebook]==1.0.10) (0.38.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->flaml[notebook]==1.0.10) (2022.6)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[notebook]==1.0.10) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->flaml[notebook]==1.0.10) (1.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (5.7.16)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (7.7.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (5.6.1)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (5.4.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (6.1.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->flaml[notebook]==1.0.10) (5.3.4)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (6.0.4)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (7.9.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (6.1.12)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->flaml[notebook]==1.0.10) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (2.6.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (57.4.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.18.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->flaml[notebook]==1.0.10) (0.2.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (3.6.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (0.2.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->flaml[notebook]==1.0.10) (3.0.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.13.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (5.7.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (1.8.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (23.2.1)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (4.11.2)\n",
            "Requirement already satisfied: jinja2<=3.0.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (2.11.3)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->flaml[notebook]==1.0.10) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2<=3.0.0->notebook->jupyter->flaml[notebook]==1.0.10) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.8.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (5.0.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (1.5.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->flaml[notebook]==1.0.10) (0.4)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (4.13.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (4.3.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (3.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (0.19.2)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (5.10.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->flaml[notebook]==1.0.10) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->flaml[notebook]==1.0.10) (0.7.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->flaml[notebook]==1.0.10) (0.5.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]==1.0.10) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]==1.0.10) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->flaml[notebook]==1.0.10) (1.4.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.26->flaml[notebook]==1.0.10) (8.1.0)\n",
            "Requirement already satisfied: qtpy>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->flaml[notebook]==1.0.10) (2.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter->flaml[notebook]==1.0.10) (21.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->openml==0.10.2->flaml[notebook]==1.0.10) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "%pip install flaml[notebook]==1.0.10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "63a48f81",
      "metadata": {
        "id": "63a48f81",
        "outputId": "c2eaec66-1df6-4c42-cea0-38e567bc63e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load dataset from ./openml_ds43926.pkl\n",
            "Dataset name: ames_housing\n",
            "X_train.shape: (2197, 80), y_train.shape: (2197,);\n",
            "X_test.shape: (733, 80), y_test.shape: (733,)\n",
            "Data type: <class 'pandas.core.frame.DataFrame'> <class 'pandas.core.series.Series'>\n",
            "The first 5 rows of X_train:\n",
            "                               MS_SubClass                   MS_Zoning  \\\n",
            "896   One_and_Half_Story_Finished_All_Ages     Residential_Low_Density   \n",
            "1901   One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
            "390    One_Story_1946_and_Newer_All_Styles     Residential_Low_Density   \n",
            "1293  One_and_Half_Story_Finished_All_Ages  Residential_Medium_Density   \n",
            "1767              Two_Story_1946_and_Newer     Residential_Low_Density   \n",
            "\n",
            "      Lot_Frontage  Lot_Area Street            Alley           Lot_Shape  \\\n",
            "896           50.0    8405.0   Pave  No_Alley_Access             Regular   \n",
            "1901          50.0    5000.0   Pave  No_Alley_Access             Regular   \n",
            "390           78.0   10140.0   Pave  No_Alley_Access             Regular   \n",
            "1293          63.0    7628.0   Pave  No_Alley_Access             Regular   \n",
            "1767         104.0   21535.0   Pave  No_Alley_Access  Slightly_Irregular   \n",
            "\n",
            "     Land_Contour Utilities Lot_Config  ...  Pool_QC            Fence  \\\n",
            "896           Lvl    AllPub     Inside  ...  No_Pool         No_Fence   \n",
            "1901          Low    AllPub     Inside  ...  No_Pool         No_Fence   \n",
            "390           Lvl    AllPub     Inside  ...  No_Pool  Minimum_Privacy   \n",
            "1293          Lvl    AllPub     Inside  ...  No_Pool         No_Fence   \n",
            "1767          Lvl    AllPub     Corner  ...  No_Pool         No_Fence   \n",
            "\n",
            "     Misc_Feature Misc_Val Mo_Sold Year_Sold Sale_Type Sale_Condition  \\\n",
            "896          None      0.0     4.0    2009.0       WD          Normal   \n",
            "1901         None      0.0     1.0    2007.0       WD          Normal   \n",
            "390          None      0.0     8.0    2009.0       WD          Normal   \n",
            "1293         None      0.0     5.0    2008.0       WD          Normal   \n",
            "1767         None      0.0     1.0    2007.0       WD          Normal   \n",
            "\n",
            "      Longitude   Latitude  \n",
            "896  -93.664456  42.021800  \n",
            "1901 -93.629661  42.036575  \n",
            "390  -93.631432  42.052670  \n",
            "1293 -93.619848  42.030418  \n",
            "1767 -93.657271  42.051980  \n",
            "\n",
            "[5 rows x 80 columns]\n",
            "The first 5 rows of y_train:\n",
            "896      98000.0\n",
            "1901     39300.0\n",
            "390     165000.0\n",
            "1293    119164.0\n",
            "1767    755000.0\n",
            "Name: Sale_Price, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import load_openml_dataset\n",
        "X_train, X_test, y_train, y_test = load_openml_dataset(dataset_id=43926, data_dir='./')\n",
        "print(\"Data type:\", type(X_train), type(y_train))\n",
        "print(\"The first 5 rows of X_train:\")\n",
        "print(X_train.head())\n",
        "print(\"The first 5 rows of y_train:\")\n",
        "print(y_train.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ca1b9330",
      "metadata": {
        "id": "ca1b9330"
      },
      "outputs": [],
      "source": [
        "from flaml import AutoML\n",
        "automl = AutoML()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "fb29dfb4",
      "metadata": {
        "id": "fb29dfb4"
      },
      "outputs": [],
      "source": [
        "settings = {\n",
        "    \"time_budget\": 600,  # total running time in seconds\n",
        "    \"metric\": 'r2',  # can be: 'r2', 'rmse', 'mae', 'mse', 'accuracy', 'roc_auc', 'roc_auc_ovr',\n",
        "                           # 'roc_auc_ovo', 'log_loss', 'mape', 'f1', 'ap', 'ndcg', 'micro_f1', 'macro_f1'\n",
        "    \"estimator_list\": ['xgboost', 'lgbm', 'catboost', 'rf'],\n",
        "    \"task\": 'regression',  # task type\n",
        "    \"log_file_name\": 'houses.log',  # flaml log file\n",
        "    \"seed\": 423874,    # random seed\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a55973e6",
      "metadata": {
        "id": "a55973e6",
        "outputId": "4f4d0a62-88af-4184-a06c-82804d9eec26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[flaml.automl: 11-23 20:40:08] {2540} INFO - task = regression\n",
            "INFO:flaml.automl:task = regression\n",
            "[flaml.automl: 11-23 20:40:08] {2542} INFO - Data split method: uniform\n",
            "INFO:flaml.automl:Data split method: uniform\n",
            "[flaml.automl: 11-23 20:40:08] {2545} INFO - Evaluation method: cv\n",
            "INFO:flaml.automl:Evaluation method: cv\n",
            "[flaml.automl: 11-23 20:40:08] {2664} INFO - Minimizing error metric: 1-r2\n",
            "INFO:flaml.automl:Minimizing error metric: 1-r2\n",
            "[flaml.automl: 11-23 20:40:08] {2806} INFO - List of ML learners in AutoML Run: ['xgboost', 'lgbm', 'catboost', 'rf']\n",
            "INFO:flaml.automl:List of ML learners in AutoML Run: ['xgboost', 'lgbm', 'catboost', 'rf']\n",
            "[flaml.automl: 11-23 20:40:08] {3108} INFO - iteration 0, current learner xgboost\n",
            "INFO:flaml.automl:iteration 0, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:09] {3242} INFO - Estimated sufficient time budget=8453s. Estimated necessary time budget=10s.\n",
            "INFO:flaml.automl:Estimated sufficient time budget=8453s. Estimated necessary time budget=10s.\n",
            "[flaml.automl: 11-23 20:40:09] {3294} INFO -  at 1.2s,\testimator xgboost's best error=2.8673,\tbest estimator xgboost's best error=2.8673\n",
            "INFO:flaml.automl: at 1.2s,\testimator xgboost's best error=2.8673,\tbest estimator xgboost's best error=2.8673\n",
            "[flaml.automl: 11-23 20:40:09] {3108} INFO - iteration 1, current learner lgbm\n",
            "INFO:flaml.automl:iteration 1, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:10] {3294} INFO -  at 2.1s,\testimator lgbm's best error=0.6227,\tbest estimator lgbm's best error=0.6227\n",
            "INFO:flaml.automl: at 2.1s,\testimator lgbm's best error=0.6227,\tbest estimator lgbm's best error=0.6227\n",
            "[flaml.automl: 11-23 20:40:10] {3108} INFO - iteration 2, current learner lgbm\n",
            "INFO:flaml.automl:iteration 2, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:11] {3294} INFO -  at 3.5s,\testimator lgbm's best error=0.6227,\tbest estimator lgbm's best error=0.6227\n",
            "INFO:flaml.automl: at 3.5s,\testimator lgbm's best error=0.6227,\tbest estimator lgbm's best error=0.6227\n",
            "[flaml.automl: 11-23 20:40:11] {3108} INFO - iteration 3, current learner rf\n",
            "INFO:flaml.automl:iteration 3, current learner rf\n",
            "[flaml.automl: 11-23 20:40:14] {3294} INFO -  at 5.7s,\testimator rf's best error=0.3395,\tbest estimator rf's best error=0.3395\n",
            "INFO:flaml.automl: at 5.7s,\testimator rf's best error=0.3395,\tbest estimator rf's best error=0.3395\n",
            "[flaml.automl: 11-23 20:40:14] {3108} INFO - iteration 4, current learner lgbm\n",
            "INFO:flaml.automl:iteration 4, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:15] {3294} INFO -  at 7.3s,\testimator lgbm's best error=0.2755,\tbest estimator lgbm's best error=0.2755\n",
            "INFO:flaml.automl: at 7.3s,\testimator lgbm's best error=0.2755,\tbest estimator lgbm's best error=0.2755\n",
            "[flaml.automl: 11-23 20:40:15] {3108} INFO - iteration 5, current learner xgboost\n",
            "INFO:flaml.automl:iteration 5, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:17] {3294} INFO -  at 8.9s,\testimator xgboost's best error=2.8673,\tbest estimator lgbm's best error=0.2755\n",
            "INFO:flaml.automl: at 8.9s,\testimator xgboost's best error=2.8673,\tbest estimator lgbm's best error=0.2755\n",
            "[flaml.automl: 11-23 20:40:17] {3108} INFO - iteration 6, current learner lgbm\n",
            "INFO:flaml.automl:iteration 6, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:19] {3294} INFO -  at 11.4s,\testimator lgbm's best error=0.2208,\tbest estimator lgbm's best error=0.2208\n",
            "INFO:flaml.automl: at 11.4s,\testimator lgbm's best error=0.2208,\tbest estimator lgbm's best error=0.2208\n",
            "[flaml.automl: 11-23 20:40:19] {3108} INFO - iteration 7, current learner xgboost\n",
            "INFO:flaml.automl:iteration 7, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:21] {3294} INFO -  at 13.3s,\testimator xgboost's best error=0.4673,\tbest estimator lgbm's best error=0.2208\n",
            "INFO:flaml.automl: at 13.3s,\testimator xgboost's best error=0.4673,\tbest estimator lgbm's best error=0.2208\n",
            "[flaml.automl: 11-23 20:40:21] {3108} INFO - iteration 8, current learner xgboost\n",
            "INFO:flaml.automl:iteration 8, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:22] {3294} INFO -  at 14.4s,\testimator xgboost's best error=0.1881,\tbest estimator xgboost's best error=0.1881\n",
            "INFO:flaml.automl: at 14.4s,\testimator xgboost's best error=0.1881,\tbest estimator xgboost's best error=0.1881\n",
            "[flaml.automl: 11-23 20:40:22] {3108} INFO - iteration 9, current learner xgboost\n",
            "INFO:flaml.automl:iteration 9, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:24] {3294} INFO -  at 15.9s,\testimator xgboost's best error=0.1881,\tbest estimator xgboost's best error=0.1881\n",
            "INFO:flaml.automl: at 15.9s,\testimator xgboost's best error=0.1881,\tbest estimator xgboost's best error=0.1881\n",
            "[flaml.automl: 11-23 20:40:24] {3108} INFO - iteration 10, current learner xgboost\n",
            "INFO:flaml.automl:iteration 10, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:27] {3294} INFO -  at 19.1s,\testimator xgboost's best error=0.1734,\tbest estimator xgboost's best error=0.1734\n",
            "INFO:flaml.automl: at 19.1s,\testimator xgboost's best error=0.1734,\tbest estimator xgboost's best error=0.1734\n",
            "[flaml.automl: 11-23 20:40:27] {3108} INFO - iteration 11, current learner lgbm\n",
            "INFO:flaml.automl:iteration 11, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:29] {3294} INFO -  at 21.0s,\testimator lgbm's best error=0.2208,\tbest estimator xgboost's best error=0.1734\n",
            "INFO:flaml.automl: at 21.0s,\testimator lgbm's best error=0.2208,\tbest estimator xgboost's best error=0.1734\n",
            "[flaml.automl: 11-23 20:40:29] {3108} INFO - iteration 12, current learner rf\n",
            "INFO:flaml.automl:iteration 12, current learner rf\n",
            "[flaml.automl: 11-23 20:40:32] {3294} INFO -  at 23.7s,\testimator rf's best error=0.2367,\tbest estimator xgboost's best error=0.1734\n",
            "INFO:flaml.automl: at 23.7s,\testimator rf's best error=0.2367,\tbest estimator xgboost's best error=0.1734\n",
            "[flaml.automl: 11-23 20:40:32] {3108} INFO - iteration 13, current learner lgbm\n",
            "INFO:flaml.automl:iteration 13, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:33] {3294} INFO -  at 25.2s,\testimator lgbm's best error=0.2208,\tbest estimator xgboost's best error=0.1734\n",
            "INFO:flaml.automl: at 25.2s,\testimator lgbm's best error=0.2208,\tbest estimator xgboost's best error=0.1734\n",
            "[flaml.automl: 11-23 20:40:33] {3108} INFO - iteration 14, current learner rf\n",
            "INFO:flaml.automl:iteration 14, current learner rf\n",
            "[flaml.automl: 11-23 20:40:36] {3294} INFO -  at 28.3s,\testimator rf's best error=0.2171,\tbest estimator xgboost's best error=0.1734\n",
            "INFO:flaml.automl: at 28.3s,\testimator rf's best error=0.2171,\tbest estimator xgboost's best error=0.1734\n",
            "[flaml.automl: 11-23 20:40:36] {3108} INFO - iteration 15, current learner xgboost\n",
            "INFO:flaml.automl:iteration 15, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:37] {3294} INFO -  at 29.5s,\testimator xgboost's best error=0.1734,\tbest estimator xgboost's best error=0.1734\n",
            "INFO:flaml.automl: at 29.5s,\testimator xgboost's best error=0.1734,\tbest estimator xgboost's best error=0.1734\n",
            "[flaml.automl: 11-23 20:40:37] {3108} INFO - iteration 16, current learner rf\n",
            "INFO:flaml.automl:iteration 16, current learner rf\n",
            "[flaml.automl: 11-23 20:40:39] {3294} INFO -  at 31.2s,\testimator rf's best error=0.2171,\tbest estimator xgboost's best error=0.1734\n",
            "INFO:flaml.automl: at 31.2s,\testimator rf's best error=0.2171,\tbest estimator xgboost's best error=0.1734\n",
            "[flaml.automl: 11-23 20:40:39] {3108} INFO - iteration 17, current learner xgboost\n",
            "INFO:flaml.automl:iteration 17, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:40] {3294} INFO -  at 31.9s,\testimator xgboost's best error=0.1623,\tbest estimator xgboost's best error=0.1623\n",
            "INFO:flaml.automl: at 31.9s,\testimator xgboost's best error=0.1623,\tbest estimator xgboost's best error=0.1623\n",
            "[flaml.automl: 11-23 20:40:40] {3108} INFO - iteration 18, current learner xgboost\n",
            "INFO:flaml.automl:iteration 18, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:40] {3294} INFO -  at 32.6s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 32.6s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:40] {3108} INFO - iteration 19, current learner xgboost\n",
            "INFO:flaml.automl:iteration 19, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:41] {3294} INFO -  at 33.3s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 33.3s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:41] {3108} INFO - iteration 20, current learner xgboost\n",
            "INFO:flaml.automl:iteration 20, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:42] {3294} INFO -  at 33.9s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 33.9s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:42] {3108} INFO - iteration 21, current learner xgboost\n",
            "INFO:flaml.automl:iteration 21, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:43] {3294} INFO -  at 34.8s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 34.8s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:43] {3108} INFO - iteration 22, current learner xgboost\n",
            "INFO:flaml.automl:iteration 22, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:43] {3294} INFO -  at 35.5s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 35.5s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:43] {3108} INFO - iteration 23, current learner lgbm\n",
            "INFO:flaml.automl:iteration 23, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:44] {3294} INFO -  at 36.0s,\testimator lgbm's best error=0.2208,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 36.0s,\testimator lgbm's best error=0.2208,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:44] {3108} INFO - iteration 24, current learner rf\n",
            "INFO:flaml.automl:iteration 24, current learner rf\n",
            "[flaml.automl: 11-23 20:40:45] {3294} INFO -  at 37.6s,\testimator rf's best error=0.2171,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 37.6s,\testimator rf's best error=0.2171,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:45] {3108} INFO - iteration 25, current learner xgboost\n",
            "INFO:flaml.automl:iteration 25, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:46] {3294} INFO -  at 38.2s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 38.2s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:46] {3108} INFO - iteration 26, current learner xgboost\n",
            "INFO:flaml.automl:iteration 26, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:47] {3294} INFO -  at 38.9s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "INFO:flaml.automl: at 38.9s,\testimator xgboost's best error=0.1502,\tbest estimator xgboost's best error=0.1502\n",
            "[flaml.automl: 11-23 20:40:47] {3108} INFO - iteration 27, current learner lgbm\n",
            "INFO:flaml.automl:iteration 27, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:47] {3294} INFO -  at 39.5s,\testimator lgbm's best error=0.1390,\tbest estimator lgbm's best error=0.1390\n",
            "INFO:flaml.automl: at 39.5s,\testimator lgbm's best error=0.1390,\tbest estimator lgbm's best error=0.1390\n",
            "[flaml.automl: 11-23 20:40:47] {3108} INFO - iteration 28, current learner lgbm\n",
            "INFO:flaml.automl:iteration 28, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:48] {3294} INFO -  at 40.0s,\testimator lgbm's best error=0.1390,\tbest estimator lgbm's best error=0.1390\n",
            "INFO:flaml.automl: at 40.0s,\testimator lgbm's best error=0.1390,\tbest estimator lgbm's best error=0.1390\n",
            "[flaml.automl: 11-23 20:40:48] {3108} INFO - iteration 29, current learner xgboost\n",
            "INFO:flaml.automl:iteration 29, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:49] {3294} INFO -  at 40.8s,\testimator xgboost's best error=0.1465,\tbest estimator lgbm's best error=0.1390\n",
            "INFO:flaml.automl: at 40.8s,\testimator xgboost's best error=0.1465,\tbest estimator lgbm's best error=0.1390\n",
            "[flaml.automl: 11-23 20:40:49] {3108} INFO - iteration 30, current learner xgboost\n",
            "INFO:flaml.automl:iteration 30, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:49] {3294} INFO -  at 41.6s,\testimator xgboost's best error=0.1465,\tbest estimator lgbm's best error=0.1390\n",
            "INFO:flaml.automl: at 41.6s,\testimator xgboost's best error=0.1465,\tbest estimator lgbm's best error=0.1390\n",
            "[flaml.automl: 11-23 20:40:49] {3108} INFO - iteration 31, current learner lgbm\n",
            "INFO:flaml.automl:iteration 31, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:50] {3294} INFO -  at 42.2s,\testimator lgbm's best error=0.1390,\tbest estimator lgbm's best error=0.1390\n",
            "INFO:flaml.automl: at 42.2s,\testimator lgbm's best error=0.1390,\tbest estimator lgbm's best error=0.1390\n",
            "[flaml.automl: 11-23 20:40:50] {3108} INFO - iteration 32, current learner lgbm\n",
            "INFO:flaml.automl:iteration 32, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:51] {3294} INFO -  at 42.7s,\testimator lgbm's best error=0.1390,\tbest estimator lgbm's best error=0.1390\n",
            "INFO:flaml.automl: at 42.7s,\testimator lgbm's best error=0.1390,\tbest estimator lgbm's best error=0.1390\n",
            "[flaml.automl: 11-23 20:40:51] {3108} INFO - iteration 33, current learner xgboost\n",
            "INFO:flaml.automl:iteration 33, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:54] {3294} INFO -  at 45.8s,\testimator xgboost's best error=0.1291,\tbest estimator xgboost's best error=0.1291\n",
            "INFO:flaml.automl: at 45.8s,\testimator xgboost's best error=0.1291,\tbest estimator xgboost's best error=0.1291\n",
            "[flaml.automl: 11-23 20:40:54] {3108} INFO - iteration 34, current learner xgboost\n",
            "INFO:flaml.automl:iteration 34, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:55] {3294} INFO -  at 46.7s,\testimator xgboost's best error=0.1291,\tbest estimator xgboost's best error=0.1291\n",
            "INFO:flaml.automl: at 46.7s,\testimator xgboost's best error=0.1291,\tbest estimator xgboost's best error=0.1291\n",
            "[flaml.automl: 11-23 20:40:55] {3108} INFO - iteration 35, current learner lgbm\n",
            "INFO:flaml.automl:iteration 35, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:55] {3294} INFO -  at 47.3s,\testimator lgbm's best error=0.1390,\tbest estimator xgboost's best error=0.1291\n",
            "INFO:flaml.automl: at 47.3s,\testimator lgbm's best error=0.1390,\tbest estimator xgboost's best error=0.1291\n",
            "[flaml.automl: 11-23 20:40:55] {3108} INFO - iteration 36, current learner lgbm\n",
            "INFO:flaml.automl:iteration 36, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:56] {3294} INFO -  at 47.9s,\testimator lgbm's best error=0.1390,\tbest estimator xgboost's best error=0.1291\n",
            "INFO:flaml.automl: at 47.9s,\testimator lgbm's best error=0.1390,\tbest estimator xgboost's best error=0.1291\n",
            "[flaml.automl: 11-23 20:40:56] {3108} INFO - iteration 37, current learner lgbm\n",
            "INFO:flaml.automl:iteration 37, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:57] {3294} INFO -  at 48.7s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "INFO:flaml.automl: at 48.7s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "[flaml.automl: 11-23 20:40:57] {3108} INFO - iteration 38, current learner lgbm\n",
            "INFO:flaml.automl:iteration 38, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:57] {3294} INFO -  at 49.3s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "INFO:flaml.automl: at 49.3s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "[flaml.automl: 11-23 20:40:57] {3108} INFO - iteration 39, current learner lgbm\n",
            "INFO:flaml.automl:iteration 39, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:58] {3294} INFO -  at 49.9s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "INFO:flaml.automl: at 49.9s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "[flaml.automl: 11-23 20:40:58] {3108} INFO - iteration 40, current learner lgbm\n",
            "INFO:flaml.automl:iteration 40, current learner lgbm\n",
            "[flaml.automl: 11-23 20:40:58] {3294} INFO -  at 50.6s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "INFO:flaml.automl: at 50.6s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "[flaml.automl: 11-23 20:40:58] {3108} INFO - iteration 41, current learner xgboost\n",
            "INFO:flaml.automl:iteration 41, current learner xgboost\n",
            "[flaml.automl: 11-23 20:40:59] {3294} INFO -  at 51.4s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.1093\n",
            "INFO:flaml.automl: at 51.4s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.1093\n",
            "[flaml.automl: 11-23 20:40:59] {3108} INFO - iteration 42, current learner lgbm\n",
            "INFO:flaml.automl:iteration 42, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:00] {3294} INFO -  at 52.2s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "INFO:flaml.automl: at 52.2s,\testimator lgbm's best error=0.1093,\tbest estimator lgbm's best error=0.1093\n",
            "[flaml.automl: 11-23 20:41:00] {3108} INFO - iteration 43, current learner rf\n",
            "INFO:flaml.automl:iteration 43, current learner rf\n",
            "[flaml.automl: 11-23 20:41:02] {3294} INFO -  at 53.8s,\testimator rf's best error=0.1827,\tbest estimator lgbm's best error=0.1093\n",
            "INFO:flaml.automl: at 53.8s,\testimator rf's best error=0.1827,\tbest estimator lgbm's best error=0.1093\n",
            "[flaml.automl: 11-23 20:41:02] {3108} INFO - iteration 44, current learner lgbm\n",
            "INFO:flaml.automl:iteration 44, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:02] {3294} INFO -  at 54.5s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
            "INFO:flaml.automl: at 54.5s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
            "[flaml.automl: 11-23 20:41:02] {3108} INFO - iteration 45, current learner lgbm\n",
            "INFO:flaml.automl:iteration 45, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:03] {3294} INFO -  at 55.1s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
            "INFO:flaml.automl: at 55.1s,\testimator lgbm's best error=0.1071,\tbest estimator lgbm's best error=0.1071\n",
            "[flaml.automl: 11-23 20:41:03] {3108} INFO - iteration 46, current learner lgbm\n",
            "INFO:flaml.automl:iteration 46, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:04] {3294} INFO -  at 55.8s,\testimator lgbm's best error=0.1006,\tbest estimator lgbm's best error=0.1006\n",
            "INFO:flaml.automl: at 55.8s,\testimator lgbm's best error=0.1006,\tbest estimator lgbm's best error=0.1006\n",
            "[flaml.automl: 11-23 20:41:04] {3108} INFO - iteration 47, current learner lgbm\n",
            "INFO:flaml.automl:iteration 47, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:04] {3294} INFO -  at 56.6s,\testimator lgbm's best error=0.1006,\tbest estimator lgbm's best error=0.1006\n",
            "INFO:flaml.automl: at 56.6s,\testimator lgbm's best error=0.1006,\tbest estimator lgbm's best error=0.1006\n",
            "[flaml.automl: 11-23 20:41:04] {3108} INFO - iteration 48, current learner lgbm\n",
            "INFO:flaml.automl:iteration 48, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:05] {3294} INFO -  at 57.3s,\testimator lgbm's best error=0.1006,\tbest estimator lgbm's best error=0.1006\n",
            "INFO:flaml.automl: at 57.3s,\testimator lgbm's best error=0.1006,\tbest estimator lgbm's best error=0.1006\n",
            "[flaml.automl: 11-23 20:41:05] {3108} INFO - iteration 49, current learner lgbm\n",
            "INFO:flaml.automl:iteration 49, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:06] {3294} INFO -  at 57.9s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "INFO:flaml.automl: at 57.9s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "[flaml.automl: 11-23 20:41:06] {3108} INFO - iteration 50, current learner lgbm\n",
            "INFO:flaml.automl:iteration 50, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:07] {3294} INFO -  at 58.8s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "INFO:flaml.automl: at 58.8s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "[flaml.automl: 11-23 20:41:07] {3108} INFO - iteration 51, current learner lgbm\n",
            "INFO:flaml.automl:iteration 51, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:09] {3294} INFO -  at 61.6s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "INFO:flaml.automl: at 61.6s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "[flaml.automl: 11-23 20:41:09] {3108} INFO - iteration 52, current learner xgboost\n",
            "INFO:flaml.automl:iteration 52, current learner xgboost\n",
            "[flaml.automl: 11-23 20:41:10] {3294} INFO -  at 62.5s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0993\n",
            "INFO:flaml.automl: at 62.5s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0993\n",
            "[flaml.automl: 11-23 20:41:10] {3108} INFO - iteration 53, current learner xgboost\n",
            "INFO:flaml.automl:iteration 53, current learner xgboost\n",
            "[flaml.automl: 11-23 20:41:11] {3294} INFO -  at 63.3s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0993\n",
            "INFO:flaml.automl: at 63.3s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0993\n",
            "[flaml.automl: 11-23 20:41:11] {3108} INFO - iteration 54, current learner lgbm\n",
            "INFO:flaml.automl:iteration 54, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:12] {3294} INFO -  at 64.0s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "INFO:flaml.automl: at 64.0s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "[flaml.automl: 11-23 20:41:12] {3108} INFO - iteration 55, current learner lgbm\n",
            "INFO:flaml.automl:iteration 55, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:13] {3294} INFO -  at 64.8s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "INFO:flaml.automl: at 64.8s,\testimator lgbm's best error=0.0993,\tbest estimator lgbm's best error=0.0993\n",
            "[flaml.automl: 11-23 20:41:13] {3108} INFO - iteration 56, current learner lgbm\n",
            "INFO:flaml.automl:iteration 56, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:14] {3294} INFO -  at 65.8s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "INFO:flaml.automl: at 65.8s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl: 11-23 20:41:14] {3108} INFO - iteration 57, current learner lgbm\n",
            "INFO:flaml.automl:iteration 57, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:14] {3294} INFO -  at 66.4s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "INFO:flaml.automl: at 66.4s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl: 11-23 20:41:14] {3108} INFO - iteration 58, current learner xgboost\n",
            "INFO:flaml.automl:iteration 58, current learner xgboost\n",
            "[flaml.automl: 11-23 20:41:15] {3294} INFO -  at 67.1s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0927\n",
            "INFO:flaml.automl: at 67.1s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl: 11-23 20:41:15] {3108} INFO - iteration 59, current learner lgbm\n",
            "INFO:flaml.automl:iteration 59, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:17] {3294} INFO -  at 69.1s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "INFO:flaml.automl: at 69.1s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl: 11-23 20:41:17] {3108} INFO - iteration 60, current learner lgbm\n",
            "INFO:flaml.automl:iteration 60, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:18] {3294} INFO -  at 70.4s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "INFO:flaml.automl: at 70.4s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl: 11-23 20:41:18] {3108} INFO - iteration 61, current learner lgbm\n",
            "INFO:flaml.automl:iteration 61, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:19] {3294} INFO -  at 71.3s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "INFO:flaml.automl: at 71.3s,\testimator lgbm's best error=0.0927,\tbest estimator lgbm's best error=0.0927\n",
            "[flaml.automl: 11-23 20:41:19] {3108} INFO - iteration 62, current learner lgbm\n",
            "INFO:flaml.automl:iteration 62, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:20] {3294} INFO -  at 72.4s,\testimator lgbm's best error=0.0918,\tbest estimator lgbm's best error=0.0918\n",
            "INFO:flaml.automl: at 72.4s,\testimator lgbm's best error=0.0918,\tbest estimator lgbm's best error=0.0918\n",
            "[flaml.automl: 11-23 20:41:20] {3108} INFO - iteration 63, current learner xgboost\n",
            "INFO:flaml.automl:iteration 63, current learner xgboost\n",
            "[flaml.automl: 11-23 20:41:21] {3294} INFO -  at 73.1s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0918\n",
            "INFO:flaml.automl: at 73.1s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0918\n",
            "[flaml.automl: 11-23 20:41:21] {3108} INFO - iteration 64, current learner lgbm\n",
            "INFO:flaml.automl:iteration 64, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:22] {3294} INFO -  at 74.1s,\testimator lgbm's best error=0.0918,\tbest estimator lgbm's best error=0.0918\n",
            "INFO:flaml.automl: at 74.1s,\testimator lgbm's best error=0.0918,\tbest estimator lgbm's best error=0.0918\n",
            "[flaml.automl: 11-23 20:41:22] {3108} INFO - iteration 65, current learner lgbm\n",
            "INFO:flaml.automl:iteration 65, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:24] {3294} INFO -  at 75.9s,\testimator lgbm's best error=0.0904,\tbest estimator lgbm's best error=0.0904\n",
            "INFO:flaml.automl: at 75.9s,\testimator lgbm's best error=0.0904,\tbest estimator lgbm's best error=0.0904\n",
            "[flaml.automl: 11-23 20:41:24] {3108} INFO - iteration 66, current learner lgbm\n",
            "INFO:flaml.automl:iteration 66, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:25] {3294} INFO -  at 77.1s,\testimator lgbm's best error=0.0904,\tbest estimator lgbm's best error=0.0904\n",
            "INFO:flaml.automl: at 77.1s,\testimator lgbm's best error=0.0904,\tbest estimator lgbm's best error=0.0904\n",
            "[flaml.automl: 11-23 20:41:25] {3108} INFO - iteration 67, current learner xgboost\n",
            "INFO:flaml.automl:iteration 67, current learner xgboost\n",
            "[flaml.automl: 11-23 20:41:26] {3294} INFO -  at 77.9s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0904\n",
            "INFO:flaml.automl: at 77.9s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0904\n",
            "[flaml.automl: 11-23 20:41:26] {3108} INFO - iteration 68, current learner lgbm\n",
            "INFO:flaml.automl:iteration 68, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:29] {3294} INFO -  at 81.3s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 81.3s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:41:29] {3108} INFO - iteration 69, current learner lgbm\n",
            "INFO:flaml.automl:iteration 69, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:31] {3294} INFO -  at 83.0s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 83.0s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:41:31] {3108} INFO - iteration 70, current learner lgbm\n",
            "INFO:flaml.automl:iteration 70, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:35] {3294} INFO -  at 87.5s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 87.5s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:41:35] {3108} INFO - iteration 71, current learner rf\n",
            "INFO:flaml.automl:iteration 71, current learner rf\n",
            "[flaml.automl: 11-23 20:41:37] {3294} INFO -  at 89.2s,\testimator rf's best error=0.1827,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 89.2s,\testimator rf's best error=0.1827,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:41:37] {3108} INFO - iteration 72, current learner lgbm\n",
            "INFO:flaml.automl:iteration 72, current learner lgbm\n",
            "[flaml.automl: 11-23 20:41:42] {3294} INFO -  at 94.0s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 94.0s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:41:42] {3108} INFO - iteration 73, current learner catboost\n",
            "INFO:flaml.automl:iteration 73, current learner catboost\n",
            "[flaml.automl: 11-23 20:42:16] {3294} INFO -  at 127.9s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 127.9s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:16] {3108} INFO - iteration 74, current learner rf\n",
            "INFO:flaml.automl:iteration 74, current learner rf\n",
            "[flaml.automl: 11-23 20:42:18] {3294} INFO -  at 129.9s,\testimator rf's best error=0.1827,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 129.9s,\testimator rf's best error=0.1827,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:18] {3108} INFO - iteration 75, current learner xgboost\n",
            "INFO:flaml.automl:iteration 75, current learner xgboost\n",
            "[flaml.automl: 11-23 20:42:19] {3294} INFO -  at 130.7s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 130.7s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:19] {3108} INFO - iteration 76, current learner lgbm\n",
            "INFO:flaml.automl:iteration 76, current learner lgbm\n",
            "[flaml.automl: 11-23 20:42:21] {3294} INFO -  at 132.7s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 132.7s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:21] {3108} INFO - iteration 77, current learner catboost\n",
            "INFO:flaml.automl:iteration 77, current learner catboost\n",
            "[flaml.automl: 11-23 20:42:38] {3294} INFO -  at 149.9s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 149.9s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:38] {3108} INFO - iteration 78, current learner lgbm\n",
            "INFO:flaml.automl:iteration 78, current learner lgbm\n",
            "[flaml.automl: 11-23 20:42:43] {3294} INFO -  at 155.4s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 155.4s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:43] {3108} INFO - iteration 79, current learner xgboost\n",
            "INFO:flaml.automl:iteration 79, current learner xgboost\n",
            "[flaml.automl: 11-23 20:42:44] {3294} INFO -  at 156.3s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 156.3s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:44] {3108} INFO - iteration 80, current learner rf\n",
            "INFO:flaml.automl:iteration 80, current learner rf\n",
            "[flaml.automl: 11-23 20:42:47] {3294} INFO -  at 158.7s,\testimator rf's best error=0.1669,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 158.7s,\testimator rf's best error=0.1669,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:47] {3108} INFO - iteration 81, current learner lgbm\n",
            "INFO:flaml.automl:iteration 81, current learner lgbm\n",
            "[flaml.automl: 11-23 20:42:51] {3294} INFO -  at 163.6s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 163.6s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:42:51] {3108} INFO - iteration 82, current learner catboost\n",
            "INFO:flaml.automl:iteration 82, current learner catboost\n",
            "[flaml.automl: 11-23 20:43:43] {3294} INFO -  at 214.7s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 214.7s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:43:43] {3108} INFO - iteration 83, current learner catboost\n",
            "INFO:flaml.automl:iteration 83, current learner catboost\n",
            "[flaml.automl: 11-23 20:44:33] {3294} INFO -  at 265.1s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 265.1s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:44:33] {3108} INFO - iteration 84, current learner rf\n",
            "INFO:flaml.automl:iteration 84, current learner rf\n",
            "[flaml.automl: 11-23 20:44:35] {3294} INFO -  at 267.1s,\testimator rf's best error=0.1669,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 267.1s,\testimator rf's best error=0.1669,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:44:35] {3108} INFO - iteration 85, current learner lgbm\n",
            "INFO:flaml.automl:iteration 85, current learner lgbm\n",
            "[flaml.automl: 11-23 20:44:38] {3294} INFO -  at 270.3s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 270.3s,\testimator lgbm's best error=0.0877,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:44:38] {3108} INFO - iteration 86, current learner catboost\n",
            "INFO:flaml.automl:iteration 86, current learner catboost\n",
            "[flaml.automl: 11-23 20:44:52] {3294} INFO -  at 284.6s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "INFO:flaml.automl: at 284.6s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0877\n",
            "[flaml.automl: 11-23 20:44:52] {3108} INFO - iteration 87, current learner lgbm\n",
            "INFO:flaml.automl:iteration 87, current learner lgbm\n",
            "[flaml.automl: 11-23 20:44:54] {3294} INFO -  at 286.2s,\testimator lgbm's best error=0.0875,\tbest estimator lgbm's best error=0.0875\n",
            "INFO:flaml.automl: at 286.2s,\testimator lgbm's best error=0.0875,\tbest estimator lgbm's best error=0.0875\n",
            "[flaml.automl: 11-23 20:44:54] {3108} INFO - iteration 88, current learner lgbm\n",
            "INFO:flaml.automl:iteration 88, current learner lgbm\n",
            "[flaml.automl: 11-23 20:44:57] {3294} INFO -  at 289.5s,\testimator lgbm's best error=0.0875,\tbest estimator lgbm's best error=0.0875\n",
            "INFO:flaml.automl: at 289.5s,\testimator lgbm's best error=0.0875,\tbest estimator lgbm's best error=0.0875\n",
            "[flaml.automl: 11-23 20:44:57] {3108} INFO - iteration 89, current learner rf\n",
            "INFO:flaml.automl:iteration 89, current learner rf\n",
            "[flaml.automl: 11-23 20:45:00] {3294} INFO -  at 291.7s,\testimator rf's best error=0.1343,\tbest estimator lgbm's best error=0.0875\n",
            "INFO:flaml.automl: at 291.7s,\testimator rf's best error=0.1343,\tbest estimator lgbm's best error=0.0875\n",
            "[flaml.automl: 11-23 20:45:00] {3108} INFO - iteration 90, current learner rf\n",
            "INFO:flaml.automl:iteration 90, current learner rf\n",
            "[flaml.automl: 11-23 20:45:02] {3294} INFO -  at 293.9s,\testimator rf's best error=0.1343,\tbest estimator lgbm's best error=0.0875\n",
            "INFO:flaml.automl: at 293.9s,\testimator rf's best error=0.1343,\tbest estimator lgbm's best error=0.0875\n",
            "[flaml.automl: 11-23 20:45:02] {3108} INFO - iteration 91, current learner rf\n",
            "INFO:flaml.automl:iteration 91, current learner rf\n",
            "[flaml.automl: 11-23 20:45:04] {3294} INFO -  at 296.3s,\testimator rf's best error=0.1343,\tbest estimator lgbm's best error=0.0875\n",
            "INFO:flaml.automl: at 296.3s,\testimator rf's best error=0.1343,\tbest estimator lgbm's best error=0.0875\n",
            "[flaml.automl: 11-23 20:45:04] {3108} INFO - iteration 92, current learner rf\n",
            "INFO:flaml.automl:iteration 92, current learner rf\n",
            "[flaml.automl: 11-23 20:45:06] {3294} INFO -  at 298.0s,\testimator rf's best error=0.1320,\tbest estimator lgbm's best error=0.0875\n",
            "INFO:flaml.automl: at 298.0s,\testimator rf's best error=0.1320,\tbest estimator lgbm's best error=0.0875\n",
            "[flaml.automl: 11-23 20:45:06] {3108} INFO - iteration 93, current learner lgbm\n",
            "INFO:flaml.automl:iteration 93, current learner lgbm\n",
            "[flaml.automl: 11-23 20:45:08] {3294} INFO -  at 300.2s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 300.2s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:45:08] {3108} INFO - iteration 94, current learner lgbm\n",
            "INFO:flaml.automl:iteration 94, current learner lgbm\n",
            "[flaml.automl: 11-23 20:45:10] {3294} INFO -  at 302.0s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 302.0s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:45:10] {3108} INFO - iteration 95, current learner catboost\n",
            "INFO:flaml.automl:iteration 95, current learner catboost\n",
            "[flaml.automl: 11-23 20:45:32] {3294} INFO -  at 323.9s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 323.9s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:45:32] {3108} INFO - iteration 96, current learner lgbm\n",
            "INFO:flaml.automl:iteration 96, current learner lgbm\n",
            "[flaml.automl: 11-23 20:45:38] {3294} INFO -  at 330.4s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 330.4s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:45:38] {3108} INFO - iteration 97, current learner lgbm\n",
            "INFO:flaml.automl:iteration 97, current learner lgbm\n",
            "[flaml.automl: 11-23 20:45:42] {3294} INFO -  at 333.9s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 333.9s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:45:42] {3108} INFO - iteration 98, current learner lgbm\n",
            "INFO:flaml.automl:iteration 98, current learner lgbm\n",
            "[flaml.automl: 11-23 20:45:43] {3294} INFO -  at 335.5s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 335.5s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:45:43] {3108} INFO - iteration 99, current learner lgbm\n",
            "INFO:flaml.automl:iteration 99, current learner lgbm\n",
            "[flaml.automl: 11-23 20:45:47] {3294} INFO -  at 338.7s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 338.7s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:45:47] {3108} INFO - iteration 100, current learner catboost\n",
            "INFO:flaml.automl:iteration 100, current learner catboost\n",
            "[flaml.automl: 11-23 20:46:03] {3294} INFO -  at 355.3s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 355.3s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:46:03] {3108} INFO - iteration 101, current learner lgbm\n",
            "INFO:flaml.automl:iteration 101, current learner lgbm\n",
            "[flaml.automl: 11-23 20:46:05] {3294} INFO -  at 357.2s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 357.2s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:46:05] {3108} INFO - iteration 102, current learner xgboost\n",
            "INFO:flaml.automl:iteration 102, current learner xgboost\n",
            "[flaml.automl: 11-23 20:46:06] {3294} INFO -  at 357.9s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 357.9s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:46:06] {3108} INFO - iteration 103, current learner lgbm\n",
            "INFO:flaml.automl:iteration 103, current learner lgbm\n",
            "[flaml.automl: 11-23 20:46:14] {3294} INFO -  at 366.3s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 366.3s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:46:14] {3108} INFO - iteration 104, current learner lgbm\n",
            "INFO:flaml.automl:iteration 104, current learner lgbm\n",
            "[flaml.automl: 11-23 20:46:15] {3294} INFO -  at 367.3s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 367.3s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:46:15] {3108} INFO - iteration 105, current learner lgbm\n",
            "INFO:flaml.automl:iteration 105, current learner lgbm\n",
            "[flaml.automl: 11-23 20:46:17] {3294} INFO -  at 369.1s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 369.1s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:46:17] {3108} INFO - iteration 106, current learner catboost\n",
            "INFO:flaml.automl:iteration 106, current learner catboost\n",
            "[flaml.automl: 11-23 20:46:52] {3294} INFO -  at 404.0s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 404.0s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:46:52] {3108} INFO - iteration 107, current learner lgbm\n",
            "INFO:flaml.automl:iteration 107, current learner lgbm\n",
            "[flaml.automl: 11-23 20:46:55] {3294} INFO -  at 407.4s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 407.4s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:46:55] {3108} INFO - iteration 108, current learner catboost\n",
            "INFO:flaml.automl:iteration 108, current learner catboost\n",
            "[flaml.automl: 11-23 20:47:07] {3294} INFO -  at 419.3s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 419.3s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:07] {3108} INFO - iteration 109, current learner lgbm\n",
            "INFO:flaml.automl:iteration 109, current learner lgbm\n",
            "[flaml.automl: 11-23 20:47:12] {3294} INFO -  at 424.1s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 424.1s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:12] {3108} INFO - iteration 110, current learner xgboost\n",
            "INFO:flaml.automl:iteration 110, current learner xgboost\n",
            "[flaml.automl: 11-23 20:47:13] {3294} INFO -  at 424.9s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 424.9s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:13] {3108} INFO - iteration 111, current learner rf\n",
            "INFO:flaml.automl:iteration 111, current learner rf\n",
            "[flaml.automl: 11-23 20:47:15] {3294} INFO -  at 427.6s,\testimator rf's best error=0.1221,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 427.6s,\testimator rf's best error=0.1221,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:15] {3108} INFO - iteration 112, current learner rf\n",
            "INFO:flaml.automl:iteration 112, current learner rf\n",
            "[flaml.automl: 11-23 20:47:19] {3294} INFO -  at 431.2s,\testimator rf's best error=0.1178,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 431.2s,\testimator rf's best error=0.1178,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:19] {3108} INFO - iteration 113, current learner rf\n",
            "INFO:flaml.automl:iteration 113, current learner rf\n",
            "[flaml.automl: 11-23 20:47:22] {3294} INFO -  at 433.7s,\testimator rf's best error=0.1167,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 433.7s,\testimator rf's best error=0.1167,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:22] {3108} INFO - iteration 114, current learner xgboost\n",
            "INFO:flaml.automl:iteration 114, current learner xgboost\n",
            "[flaml.automl: 11-23 20:47:22] {3294} INFO -  at 434.4s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 434.4s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:22] {3108} INFO - iteration 115, current learner xgboost\n",
            "INFO:flaml.automl:iteration 115, current learner xgboost\n",
            "[flaml.automl: 11-23 20:47:23] {3294} INFO -  at 435.6s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 435.6s,\testimator xgboost's best error=0.1291,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:23] {3108} INFO - iteration 116, current learner rf\n",
            "INFO:flaml.automl:iteration 116, current learner rf\n",
            "[flaml.automl: 11-23 20:47:26] {3294} INFO -  at 438.4s,\testimator rf's best error=0.1117,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 438.4s,\testimator rf's best error=0.1117,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:26] {3108} INFO - iteration 117, current learner rf\n",
            "INFO:flaml.automl:iteration 117, current learner rf\n",
            "[flaml.automl: 11-23 20:47:30] {3294} INFO -  at 441.7s,\testimator rf's best error=0.1117,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 441.7s,\testimator rf's best error=0.1117,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:30] {3108} INFO - iteration 118, current learner xgboost\n",
            "INFO:flaml.automl:iteration 118, current learner xgboost\n",
            "[flaml.automl: 11-23 20:47:31] {3294} INFO -  at 442.8s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 442.8s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:31] {3108} INFO - iteration 119, current learner catboost\n",
            "INFO:flaml.automl:iteration 119, current learner catboost\n",
            "[flaml.automl: 11-23 20:47:43] {3294} INFO -  at 455.1s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 455.1s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:43] {3108} INFO - iteration 120, current learner catboost\n",
            "INFO:flaml.automl:iteration 120, current learner catboost\n",
            "[flaml.automl: 11-23 20:47:51] {3294} INFO -  at 463.4s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 463.4s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:51] {3108} INFO - iteration 121, current learner rf\n",
            "INFO:flaml.automl:iteration 121, current learner rf\n",
            "[flaml.automl: 11-23 20:47:55] {3294} INFO -  at 467.1s,\testimator rf's best error=0.1088,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 467.1s,\testimator rf's best error=0.1088,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:47:55] {3108} INFO - iteration 122, current learner lgbm\n",
            "INFO:flaml.automl:iteration 122, current learner lgbm\n",
            "[flaml.automl: 11-23 20:48:00] {3294} INFO -  at 472.4s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 472.4s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:00] {3108} INFO - iteration 123, current learner xgboost\n",
            "INFO:flaml.automl:iteration 123, current learner xgboost\n",
            "[flaml.automl: 11-23 20:48:01] {3294} INFO -  at 473.3s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 473.3s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:01] {3108} INFO - iteration 124, current learner xgboost\n",
            "INFO:flaml.automl:iteration 124, current learner xgboost\n",
            "[flaml.automl: 11-23 20:48:02] {3294} INFO -  at 474.2s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 474.2s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:02] {3108} INFO - iteration 125, current learner xgboost\n",
            "INFO:flaml.automl:iteration 125, current learner xgboost\n",
            "[flaml.automl: 11-23 20:48:03] {3294} INFO -  at 475.1s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 475.1s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:03] {3108} INFO - iteration 126, current learner xgboost\n",
            "INFO:flaml.automl:iteration 126, current learner xgboost\n",
            "[flaml.automl: 11-23 20:48:04] {3294} INFO -  at 476.0s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 476.0s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:04] {3108} INFO - iteration 127, current learner xgboost\n",
            "INFO:flaml.automl:iteration 127, current learner xgboost\n",
            "[flaml.automl: 11-23 20:48:05] {3294} INFO -  at 477.2s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 477.2s,\testimator xgboost's best error=0.1140,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:05] {3108} INFO - iteration 128, current learner rf\n",
            "INFO:flaml.automl:iteration 128, current learner rf\n",
            "[flaml.automl: 11-23 20:48:08] {3294} INFO -  at 479.9s,\testimator rf's best error=0.1052,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 479.9s,\testimator rf's best error=0.1052,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:08] {3108} INFO - iteration 129, current learner catboost\n",
            "INFO:flaml.automl:iteration 129, current learner catboost\n",
            "[flaml.automl: 11-23 20:48:36] {3294} INFO -  at 508.1s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 508.1s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:36] {3108} INFO - iteration 130, current learner catboost\n",
            "INFO:flaml.automl:iteration 130, current learner catboost\n",
            "[flaml.automl: 11-23 20:48:49] {3294} INFO -  at 521.6s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 521.6s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:49] {3108} INFO - iteration 131, current learner rf\n",
            "INFO:flaml.automl:iteration 131, current learner rf\n",
            "[flaml.automl: 11-23 20:48:51] {3294} INFO -  at 523.2s,\testimator rf's best error=0.1052,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 523.2s,\testimator rf's best error=0.1052,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:51] {3108} INFO - iteration 132, current learner xgboost\n",
            "INFO:flaml.automl:iteration 132, current learner xgboost\n",
            "[flaml.automl: 11-23 20:48:52] {3294} INFO -  at 524.2s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 524.2s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:52] {3108} INFO - iteration 133, current learner xgboost\n",
            "INFO:flaml.automl:iteration 133, current learner xgboost\n",
            "[flaml.automl: 11-23 20:48:53] {3294} INFO -  at 525.3s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 525.3s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:53] {3108} INFO - iteration 134, current learner lgbm\n",
            "INFO:flaml.automl:iteration 134, current learner lgbm\n",
            "[flaml.automl: 11-23 20:48:54] {3294} INFO -  at 526.6s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 526.6s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:54] {3108} INFO - iteration 135, current learner rf\n",
            "INFO:flaml.automl:iteration 135, current learner rf\n",
            "[flaml.automl: 11-23 20:48:59] {3294} INFO -  at 531.3s,\testimator rf's best error=0.1040,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 531.3s,\testimator rf's best error=0.1040,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:48:59] {3108} INFO - iteration 136, current learner xgboost\n",
            "INFO:flaml.automl:iteration 136, current learner xgboost\n",
            "[flaml.automl: 11-23 20:49:00] {3294} INFO -  at 532.2s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 532.2s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:49:00] {3108} INFO - iteration 137, current learner xgboost\n",
            "INFO:flaml.automl:iteration 137, current learner xgboost\n",
            "[flaml.automl: 11-23 20:49:01] {3294} INFO -  at 533.5s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 533.5s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:49:01] {3108} INFO - iteration 138, current learner lgbm\n",
            "INFO:flaml.automl:iteration 138, current learner lgbm\n",
            "[flaml.automl: 11-23 20:49:06] {3294} INFO -  at 537.8s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 537.8s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:49:06] {3108} INFO - iteration 139, current learner xgboost\n",
            "INFO:flaml.automl:iteration 139, current learner xgboost\n",
            "[flaml.automl: 11-23 20:49:07] {3294} INFO -  at 538.9s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 538.9s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:49:07] {3108} INFO - iteration 140, current learner lgbm\n",
            "INFO:flaml.automl:iteration 140, current learner lgbm\n",
            "[flaml.automl: 11-23 20:49:12] {3294} INFO -  at 544.1s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 544.1s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:49:12] {3108} INFO - iteration 141, current learner xgboost\n",
            "INFO:flaml.automl:iteration 141, current learner xgboost\n",
            "[flaml.automl: 11-23 20:49:13] {3294} INFO -  at 545.0s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 545.0s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:49:13] {3108} INFO - iteration 142, current learner catboost\n",
            "INFO:flaml.automl:iteration 142, current learner catboost\n",
            "[flaml.automl: 11-23 20:50:04] {3294} INFO -  at 595.9s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 595.9s,\testimator catboost's best error=0.0880,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:50:04] {3108} INFO - iteration 143, current learner lgbm\n",
            "INFO:flaml.automl:iteration 143, current learner lgbm\n",
            "[flaml.automl: 11-23 20:50:06] {3294} INFO -  at 598.1s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 598.1s,\testimator lgbm's best error=0.0862,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:50:06] {3108} INFO - iteration 144, current learner xgboost\n",
            "INFO:flaml.automl:iteration 144, current learner xgboost\n",
            "[flaml.automl: 11-23 20:50:07] {3294} INFO -  at 599.5s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "INFO:flaml.automl: at 599.5s,\testimator xgboost's best error=0.1022,\tbest estimator lgbm's best error=0.0862\n",
            "[flaml.automl: 11-23 20:50:08] {3554} INFO - retrain lgbm for 0.4s\n",
            "INFO:flaml.automl:retrain lgbm for 0.4s\n",
            "[flaml.automl: 11-23 20:50:08] {3559} INFO - retrained model: LGBMRegressor(colsample_bytree=0.8485192283640752,\n",
            "              learning_rate=0.0694024322956206, max_bin=127,\n",
            "              min_child_samples=71, n_estimators=563, num_leaves=5,\n",
            "              reg_alpha=0.2009534125903372, reg_lambda=3.5161945937454018,\n",
            "              verbose=-1)\n",
            "INFO:flaml.automl:retrained model: LGBMRegressor(colsample_bytree=0.8485192283640752,\n",
            "              learning_rate=0.0694024322956206, max_bin=127,\n",
            "              min_child_samples=71, n_estimators=563, num_leaves=5,\n",
            "              reg_alpha=0.2009534125903372, reg_lambda=3.5161945937454018,\n",
            "              verbose=-1)\n",
            "[flaml.automl: 11-23 20:50:08] {2837} INFO - fit succeeded\n",
            "INFO:flaml.automl:fit succeeded\n",
            "[flaml.automl: 11-23 20:50:08] {2839} INFO - Time taken to find the best model: 300.22202587127686\n",
            "INFO:flaml.automl:Time taken to find the best model: 300.22202587127686\n"
          ]
        }
      ],
      "source": [
        "automl.fit(X_train, y_train, **settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ddc970f6",
      "metadata": {
        "id": "ddc970f6",
        "outputId": "0406edaf-8823-4842-aa8e-1aee7824bad6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ML leaner: lgbm\n",
            "Best hyperparmeter config: {'n_estimators': 563, 'num_leaves': 5, 'min_child_samples': 71, 'learning_rate': 0.0694024322956206, 'log_max_bin': 7, 'colsample_bytree': 0.8485192283640752, 'reg_alpha': 0.2009534125903372, 'reg_lambda': 3.5161945937454018}\n",
            "Best r2 accuracy on validation data: 0.9138\n",
            "Training duration of best run: 0.4495 s\n"
          ]
        }
      ],
      "source": [
        "print('Best ML leaner:', automl.best_estimator)\n",
        "print('Best hyperparmeter config:', automl.best_config)\n",
        "print('Best r2 accuracy on validation data: {0:.4g}'.format(1-automl.best_loss))\n",
        "print('Training duration of best run: {0:.4g} s'.format(automl.best_config_train_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ac00e5f0",
      "metadata": {
        "id": "ac00e5f0",
        "outputId": "d2283e28-4abf-4ed0-9660-6d43798392d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 80 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.barh(automl.feature_names_in_, automl.feature_importances_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0946e9bf",
      "metadata": {
        "id": "0946e9bf",
        "outputId": "2102f4b8-7fce-461f-a701-107c2bd3d2e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels [188559.61767832 153010.70412858 276941.96808972 132234.17357413\n",
            "  94164.91301945 182310.3077009   36818.96188179 132002.55832555\n",
            " 164343.10928408 107217.99776768 219481.59490084 132840.57261629\n",
            " 313233.16078135 145629.80253534 209475.00385466 146789.67209763\n",
            " 174409.11160666 125212.67558185 201299.08879092 116269.01330741\n",
            " 192608.73407864 335842.98998241 213957.04729358 154597.90734742\n",
            " 199782.31124708 124153.85482577 208899.12994924 297622.18584517\n",
            " 299665.10475233 437140.8253326  191324.06964535 237301.24102269\n",
            " 119733.64031913 116087.57651555 177302.12293967 205428.29580426\n",
            " 194085.73067473 161579.54224741 200166.19977057 168040.25916189\n",
            " 298630.71705286 138552.0470258  337148.27100389 205350.45173204\n",
            " 268452.15035418 477699.48582474 137556.32784487 253092.52580532\n",
            " 132433.47462831 203956.49950397 132558.22818671 101665.77245115\n",
            " 139299.38581469 246498.87035997 151649.10630594 112890.28516888\n",
            " 337302.80221318 111460.40315563  92205.19280857 252732.88366677\n",
            " 210193.40912464 150538.13902604  56473.18323638 121853.20231014\n",
            " 130988.64395165 140906.62705174 128686.3033057  161710.87195672\n",
            " 204925.85708737 171966.22047696 163146.05930749 145699.49572285\n",
            " 205482.85613337 145291.4034387  201556.49162712 300779.18271659\n",
            " 160410.40844581 218316.24471925 151998.08648424 227581.02614059\n",
            " 137096.52876903  93733.14754158 157971.84335088 154650.22486929\n",
            " 112064.23746215 117527.72850604 147726.5348119  145092.16892557\n",
            " 200899.97659575 243918.36763862 183706.35938303 141292.99421086\n",
            " 130609.00253232 148284.24798579 323337.96768889 135758.89624391\n",
            " 167334.53575828 172762.4972135  192849.38083109 336889.26579301\n",
            " 262752.76957623  79528.9312793   87889.15719645 232802.73298449\n",
            " 136324.8715332  169231.35138652 208285.14023241 146834.99517861\n",
            " 139352.38719735 149672.28294705  90120.21766782 227322.07847568\n",
            " 171631.05229646 228836.29033     94345.08096527 269900.39388973\n",
            " 132783.81676678 140152.74087038 160439.91012026  92729.03124255\n",
            " 120837.87642917 196171.69082129 253556.17038327 177928.77473645\n",
            " 185625.87267845 166820.01983827 249736.29617115 323103.61784788\n",
            " 369943.26550367 130698.38607504 371939.62361141 192635.36939934\n",
            " 121727.45815436 216711.60631244 129818.12953348 112785.77519734\n",
            " 492164.58942212 172129.05099718 337381.38865667 197000.10948219\n",
            " 130807.96103115 218490.80222368 364232.13968552 192074.51621864\n",
            " 136598.91217466 156613.40153121 178047.34710708 165215.27036261\n",
            " 125357.56313035 162740.85216485 202579.64071469 157160.45016957\n",
            " 211548.52794654 184604.2694103  141287.38487825 125454.1207109\n",
            "  83006.25818941 365432.0993844  309331.08704841 171208.089448\n",
            " 108147.32901207 172643.57350396 160317.6253591  140935.62671122\n",
            " 133918.04054098 141369.39228866  92821.18862227 182834.09547499\n",
            " 122419.18670417 137736.34976404 144706.45045007  76067.15631982\n",
            " 206020.35268336 147192.21954445 312220.5825186  361923.96953012\n",
            " 150195.11973069 235746.77579763 186741.71884926 118807.36540985\n",
            " 135557.79319207 454439.80947553 206608.43886396 239114.63951145\n",
            "  40200.17409201 127593.52199855 192283.38224109 112761.88942378\n",
            " 169631.09860042 268938.78370356 189650.89243266 237151.51030701\n",
            " 126394.64211002 135828.06870545 455510.4741525  205767.19918789\n",
            " 141740.60132298 225669.09581689 293099.70978049 119711.83652305\n",
            " 184155.70394917 136925.00076635 156557.41288191 213669.37673417\n",
            " 259347.28056883 190175.37363023 153279.66701712 223226.8250836\n",
            " 224837.23194831 160019.03038978 365890.5260745  293361.07783125\n",
            " 128978.63522651 197572.08637556 143042.2197634  199846.37802612\n",
            " 135809.02400421 169048.61478058 152861.41396871 140540.87327277\n",
            " 143898.2934792  140437.78256208 355880.96595831 146277.35514968\n",
            " 455368.99861581 187510.96059552 291171.12837821 229017.94231251\n",
            " 183192.77016854 271684.58493216 105073.55428226 186745.15297968\n",
            " 153041.84490093 121458.18855524 123359.06245582 136713.38994579\n",
            " 174563.46660733  76542.43491463  72669.65267937 110315.16271188\n",
            "  66513.41758222 165153.73906843 112588.05687715 270188.52289853\n",
            " 140068.81542629 129411.83486995  77216.55720939 310229.73077736\n",
            " 206646.05114712 319127.12019287 156550.90204222 129358.29282132\n",
            "  77417.03591475 137008.82841776 107181.19197198 156939.29574351\n",
            " 152654.08537897 205502.99374401 142628.55712782 179696.20734309\n",
            " 200814.77253869 210494.99535123 266879.03097437 200009.53221894\n",
            " 184124.74434471 211277.1992513  132247.62026481 240769.24703696\n",
            " 257129.82418032 203796.26754125 122492.45215575 131529.0649548\n",
            " 148251.42149912 145454.21535989 219839.74472526 253551.53247751\n",
            " 192084.35766055  76307.54216114 321867.30158124 163933.45446529\n",
            " 124158.6858857  130926.02193808 122167.98206893 251419.90333794\n",
            " 170591.20013209 288099.99330998 179738.24474779 216459.96167648\n",
            " 162083.12553328 166083.04952969 133407.99412573 109666.67221222\n",
            " 145505.12392741  75543.1088758  107939.24218084 140723.82925709\n",
            " 276489.17022006 160553.12072036 210782.94838151 199676.75607193\n",
            " 321594.12700625 120662.46431847 226302.93496678 128345.1811331\n",
            " 162868.90205469 114808.43882554 368466.2807399  108900.5080279\n",
            " 210642.47507724 113097.78881719 303995.95441919 169607.02134161\n",
            " 124463.57188672 117233.37343826 210896.02257403 121168.11136471\n",
            " 235632.80561854 148217.63460839 232359.65002377 176317.12893931\n",
            "  94822.65773559  99871.92092193 143673.03334389 158710.8583868\n",
            " 127929.70975892 190315.03226435 117994.47539011 112158.59901888\n",
            " 219606.0289381  131529.63552083 191174.05898343 126940.30201196\n",
            " 155485.1420787  218903.79521943 116421.68673369 158113.42284509\n",
            " 129557.40242415 101497.24121984  94154.28310995 130470.28776901\n",
            " 234848.48125604 237905.09971782  88856.1774066  107903.7388928\n",
            " 169566.4681983  130551.95002407 110180.76467927 205281.88645992\n",
            " 196655.44770137 198645.2585471  153443.20833958 138048.19570091\n",
            " 128766.84225298 225914.8855661  174337.01530218 153614.97463336\n",
            " 188227.71836182 215393.19203141 189211.53997931 300230.41893157\n",
            " 255495.91115259 159187.44541135 120079.8337146  223074.82691642\n",
            " 119327.64308694 154069.5390988  105948.14387586 275543.08628818\n",
            " 122489.2995908  165818.63910449 140696.60771062 399701.86375164\n",
            " 384920.11992265 138052.63064306 215623.64145068 363539.66870679\n",
            " 171959.00150879 177515.20618164 198412.0339822  238867.13034973\n",
            " 162499.73869098 146343.4064501  105208.13516817 192141.3225443\n",
            " 151152.84611917 140201.64566944 450829.96006444  79611.38947856\n",
            " 132415.05425028 260469.48631195 244547.4290835  138023.33721687\n",
            " 180198.46095881 125217.68912098 194179.49638999 137639.52660197\n",
            " 125649.61795132 349362.46888205 237214.58852392 194441.35256637\n",
            " 119012.00977693 130332.12193522 443842.92593012 129516.48978688\n",
            " 197521.00964466 246658.05729808 177769.96768602 119613.5147824\n",
            " 177215.1421137  220587.51325729  87799.50728647 113803.25248366\n",
            " 195161.41199081 280730.90838537 136926.17212769 319288.98522215\n",
            " 129423.05257965 122650.65828205 112174.15517364 220086.19552643\n",
            " 213344.82116902 359848.10653802 132826.50823511 168265.12451758\n",
            " 132649.72146761  83079.13839303 189101.73945931 417947.17345207\n",
            " 144223.34165508 313817.77422123 140254.74092081  90440.11130417\n",
            " 130566.3888188  151796.16020488 117563.9564928  107730.63311139\n",
            " 379700.92694296 251083.13214016 195829.58868516 144734.43211774\n",
            " 117861.42742894 176817.0142774  234383.45099245 210995.6150745\n",
            " 195423.19417318 155654.80305245 126535.47667233 164840.89511884\n",
            " 138113.61903154 140893.49858204 124197.71756689 133467.74020815\n",
            " 153199.73993097  67868.94434165 133766.3328997   92295.66906456\n",
            " 267175.39732878 205423.22194743 116051.38244677 196376.57546916\n",
            " 129214.17313758 177225.74821722 243992.68404893 198423.90490388\n",
            " 111868.19836197  91429.09780005 162521.14411312 138124.90030901\n",
            " 379267.91343436 167682.40395055 171153.80873604  90483.94888159\n",
            " 258065.63697399 212339.62309194 135921.91565126 129392.0867245\n",
            " 500455.8016049  272313.71942792 142630.32709237 282792.17818162\n",
            " 138027.53173359 166188.49485765  53793.65389983 175037.19478869\n",
            " 140582.40199285 120107.63691569 142081.4460798  380288.48396004\n",
            " 249289.59630217 385207.97018353 115326.73171423 166345.1510681\n",
            " 136277.93906704 164242.81320318 184301.59214524 148917.47229544\n",
            " 167335.64593957 370897.74916263 269139.53100337 123977.23685607\n",
            " 237159.30565739 153367.42209457  85769.78237391 168383.75356896\n",
            " 109659.78886184 117026.87626533  73105.47709227 145452.16373154\n",
            " 244177.45640154 163025.29937869 154585.42518302 345332.03112347\n",
            " 248563.28714019 110775.40769589 197151.83773929 172358.42910083\n",
            " 115068.38087595  75114.23086444 186322.31844029 197970.67374629\n",
            " 119125.18914065 162927.50348106 186532.67022408 137526.53948438\n",
            " 375355.73446849 170334.23736377 213381.75236214 142889.76414396\n",
            " 199181.37992271 142326.32331717 169443.69725388 135054.18902066\n",
            " 145184.1679878  209955.99009921 106659.90007356 144437.2689133\n",
            " 201325.94216893 166013.47793898 230961.28252491 140722.82220294\n",
            " 107379.73266613 135849.90723703  65513.98687954 177032.98049247\n",
            " 152284.53546191 204927.159038   236767.01827975 186449.86443759\n",
            "  97158.61670165 195202.83051467 447292.03310332  83343.97870938\n",
            " 325459.49696537 103724.36457096 180774.83045909 230215.78248709\n",
            " 441069.40524546 139910.43989153  70432.73815091 185305.80503763\n",
            " 189479.47962459 220808.24495948 121187.38572556 186335.20214462\n",
            " 361020.07250861 107752.07281904 199247.43238642 277147.62327625\n",
            " 148892.88285685 234292.18956847 168884.49568561 462519.85849112\n",
            " 105900.18086907 104721.21695018 220315.31216633 165172.63804888\n",
            " 127953.88688611 107132.66537159 140691.94244674 207547.41961655\n",
            " 200099.53314821 183345.36821622 151632.06272866 192257.37828765\n",
            " 194809.0936886  252232.33772061 213542.16333037 224147.07638605\n",
            " 121883.04470127 331153.44450768 126068.30175838 180227.1047288\n",
            " 211459.51718439 166823.12837201 120377.05968092 113498.10436821\n",
            " 351045.76483328 113332.27702129 128936.98280352 115174.44225668\n",
            " 146170.75822336 247277.66013212 474526.30476592 120177.60352968\n",
            "  77790.22728262 335904.41375691  55584.64858644  71942.07922753\n",
            " 321859.85556407 269668.2796211  235646.87276324 297674.64971558\n",
            " 179133.10162315 173993.19531926 101537.39991735 283423.51956834\n",
            " 271669.07575904  69465.33529302 119435.56165837 188317.08313365\n",
            " 101834.71017085  90712.28464955 188471.48200639 304330.45954831\n",
            " 176431.55190859 142309.05585563 189426.99126165 163769.15679097\n",
            " 183868.2609954  105939.80475712 177623.42277796 164501.79276332\n",
            " 197901.1246613  228398.48910707  80990.84145714 171445.38134536\n",
            " 163349.35786569 211655.9123266  130896.02319178 141319.90801264\n",
            " 133483.35550517 135885.6887504  262094.65638171 110948.42825671\n",
            "  80871.50605498 251231.63436898 235827.07333443 182652.20294909\n",
            " 281330.689682   195489.26541823 330768.43544512 229517.81687789\n",
            "  86518.91009476 206062.29216047 117688.01303648 124371.28058218\n",
            "  98404.39142183 215618.64998455 173970.44570202 211753.21826615\n",
            " 172332.57094486 144356.13981347 127431.94770824 188153.03664458\n",
            " 170595.04655593 135730.7833507  133403.3648131  100947.78073032\n",
            " 137415.38463058 200468.80173709 247681.82989614 145685.73234259\n",
            " 140948.1666391  189672.95199544 133086.91012159 122859.54472589\n",
            "  71831.47644042 128994.32441547 228424.04742757 189953.11236766\n",
            " 239106.73610181 351548.51809001  92513.99482335 318630.22030934\n",
            " 113992.91939262 123425.98889772 138005.59789694 212306.43662737\n",
            " 194108.08118167 163749.6904863  173082.54724954  75881.48597757\n",
            " 230758.7046648  137148.72907144 119558.30706899  97270.96169704\n",
            " 162640.22026743 127752.47333315 155719.10397314 143567.08085856\n",
            " 131869.97718455 225576.58337003 114950.9639639  191322.89527336\n",
            " 159409.2385317  185915.76193464 276471.98782823 122522.9490979\n",
            " 120795.63323939 181531.59267257 140243.47086206  89299.13409072\n",
            " 224906.91862043 303724.15342212 121745.09322397 270081.61811488\n",
            " 125698.34304961  69636.66655831 113703.30176485 297206.08953124\n",
            " 212074.89695413 310891.07149528 148516.59200077 135464.90657387\n",
            " 145260.56312472 130784.43535778 177463.08051166 145028.06926913\n",
            " 179250.71952534  95176.2158176  130219.72163045 207817.52276299\n",
            " 120825.66923002]\n",
            "True labels 2216    220000.0\n",
            "836     143000.0\n",
            "2396    281000.0\n",
            "1962    135000.0\n",
            "305     102776.0\n",
            "          ...   \n",
            "991     206900.0\n",
            "2286    106500.0\n",
            "2629    146000.0\n",
            "2776    196000.0\n",
            "1362    120000.0\n",
            "Name: Sale_Price, Length: 733, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "y_pred = automl.predict(X_test)\n",
        "print('Predicted labels', y_pred)\n",
        "print('True labels', y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a425ecdb",
      "metadata": {
        "id": "a425ecdb",
        "outputId": "145ddb92-97a6-4f60-dbcb-bb0693894bcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r2 = 0.8851201052892462\n",
            "mse = 748746104.4039737\n",
            "mae = 15136.546803986184\n"
          ]
        }
      ],
      "source": [
        "from flaml.ml import sklearn_metric_loss_score\n",
        "#print('accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred, y_test))\n",
        "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
        "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5c8e7baa",
      "metadata": {
        "id": "5c8e7baa",
        "outputId": "91da56d8-84f6-4208-e3ce-5397f6bb916c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Current Learner': 'xgboost', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 4, 'min_child_weight': 0.9999999999999993, 'learning_rate': 0.09999999999999995, 'subsample': 1.0, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 4, 'num_leaves': 4, 'min_child_samples': 20, 'learning_rate': 0.09999999999999995, 'log_max_bin': 8, 'colsample_bytree': 1.0, 'reg_alpha': 0.0009765625, 'reg_lambda': 1.0}}\n",
            "{'Current Learner': 'rf', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4}, 'Best Learner': 'rf', 'Best Hyper-parameters': {'n_estimators': 4, 'max_features': 1.0, 'max_leaves': 4}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 7, 'num_leaves': 4, 'min_child_samples': 28, 'learning_rate': 0.20176123704491705, 'log_max_bin': 7, 'colsample_bytree': 0.9314232379468054, 'reg_alpha': 0.0012314819445617192, 'reg_lambda': 9.114157883298441}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 7, 'num_leaves': 4, 'min_child_samples': 28, 'learning_rate': 0.20176123704491705, 'log_max_bin': 7, 'colsample_bytree': 0.9314232379468054, 'reg_alpha': 0.0012314819445617192, 'reg_lambda': 9.114157883298441}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 5, 'num_leaves': 4, 'min_child_samples': 61, 'learning_rate': 0.36577797144209806, 'log_max_bin': 8, 'colsample_bytree': 0.937620536138218, 'reg_alpha': 0.002576372585734981, 'reg_lambda': 5.496308954481066}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 5, 'num_leaves': 4, 'min_child_samples': 61, 'learning_rate': 0.36577797144209806, 'log_max_bin': 8, 'colsample_bytree': 0.937620536138218, 'reg_alpha': 0.002576372585734981, 'reg_lambda': 5.496308954481066}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 4, 'max_leaves': 13, 'min_child_weight': 7.7498252354192525, 'learning_rate': 0.5614525792907483, 'subsample': 0.8682107206706305, 'colsample_bylevel': 0.9814926103574051, 'colsample_bytree': 0.9637227875682511, 'reg_alpha': 0.01901656243042618, 'reg_lambda': 7.905641865583111}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 4, 'max_leaves': 13, 'min_child_weight': 7.7498252354192525, 'learning_rate': 0.5614525792907483, 'subsample': 0.8682107206706305, 'colsample_bylevel': 0.9814926103574051, 'colsample_bytree': 0.9637227875682511, 'reg_alpha': 0.01901656243042618, 'reg_lambda': 7.905641865583111}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 6, 'max_leaves': 12, 'min_child_weight': 3.707235860192951, 'learning_rate': 1.0, 'subsample': 0.7878874528230279, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.05325254338822948, 'reg_lambda': 8.866834004664607}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 6, 'max_leaves': 12, 'min_child_weight': 3.707235860192951, 'learning_rate': 1.0, 'subsample': 0.7878874528230279, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.05325254338822948, 'reg_lambda': 8.866834004664607}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 14, 'max_leaves': 5, 'min_child_weight': 6.665492288175772, 'learning_rate': 1.0, 'subsample': 0.9071232967989242, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8605666571158497, 'reg_alpha': 0.06323438911769533, 'reg_lambda': 10.490274339687272}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 14, 'max_leaves': 5, 'min_child_weight': 6.665492288175772, 'learning_rate': 1.0, 'subsample': 0.9071232967989242, 'colsample_bylevel': 1.0, 'colsample_bytree': 0.8605666571158497, 'reg_alpha': 0.06323438911769533, 'reg_lambda': 10.490274339687272}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 6, 'max_leaves': 12, 'min_child_weight': 3.707235860192951, 'learning_rate': 0.6389115380017092, 'subsample': 0.7878874528230279, 'colsample_bylevel': 0.9088719696711929, 'colsample_bytree': 1.0, 'reg_alpha': 0.05325254338822948, 'reg_lambda': 8.866834004664607}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 6, 'max_leaves': 12, 'min_child_weight': 3.707235860192951, 'learning_rate': 0.6389115380017092, 'subsample': 0.7878874528230279, 'colsample_bylevel': 0.9088719696711929, 'colsample_bytree': 1.0, 'reg_alpha': 0.05325254338822948, 'reg_lambda': 8.866834004664607}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 10, 'num_leaves': 8, 'min_child_samples': 64, 'learning_rate': 0.9066696189728185, 'log_max_bin': 7, 'colsample_bytree': 0.9852294397150869, 'reg_alpha': 0.006110983064294122, 'reg_lambda': 32.28308014313476}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 10, 'num_leaves': 8, 'min_child_samples': 64, 'learning_rate': 0.9066696189728185, 'log_max_bin': 7, 'colsample_bytree': 0.9852294397150869, 'reg_alpha': 0.006110983064294122, 'reg_lambda': 32.28308014313476}}\n",
            "{'Current Learner': 'xgboost', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 8, 'max_leaves': 27, 'min_child_weight': 34.274696752493746, 'learning_rate': 0.5766962208524447, 'subsample': 0.810892833357021, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.04312428557276985, 'reg_lambda': 7.47887051897742}, 'Best Learner': 'xgboost', 'Best Hyper-parameters': {'n_estimators': 8, 'max_leaves': 27, 'min_child_weight': 34.274696752493746, 'learning_rate': 0.5766962208524447, 'subsample': 0.810892833357021, 'colsample_bylevel': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0.04312428557276985, 'reg_lambda': 7.47887051897742}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 38, 'num_leaves': 7, 'min_child_samples': 84, 'learning_rate': 0.6322336116466368, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.0023752875571034842, 'reg_lambda': 15.61912193576279}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 38, 'num_leaves': 7, 'min_child_samples': 84, 'learning_rate': 0.6322336116466368, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.0023752875571034842, 'reg_lambda': 15.61912193576279}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 45, 'num_leaves': 4, 'min_child_samples': 73, 'learning_rate': 0.3180828257872239, 'log_max_bin': 6, 'colsample_bytree': 1.0, 'reg_alpha': 0.024028844301576698, 'reg_lambda': 40.4979294131408}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 45, 'num_leaves': 4, 'min_child_samples': 73, 'learning_rate': 0.3180828257872239, 'log_max_bin': 6, 'colsample_bytree': 1.0, 'reg_alpha': 0.024028844301576698, 'reg_lambda': 40.4979294131408}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 64, 'num_leaves': 4, 'min_child_samples': 49, 'learning_rate': 0.4370613844469147, 'log_max_bin': 7, 'colsample_bytree': 0.9923970070639831, 'reg_alpha': 0.0042542520794668, 'reg_lambda': 5.431801109350407}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 64, 'num_leaves': 4, 'min_child_samples': 49, 'learning_rate': 0.4370613844469147, 'log_max_bin': 7, 'colsample_bytree': 0.9923970070639831, 'reg_alpha': 0.0042542520794668, 'reg_lambda': 5.431801109350407}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 66, 'num_leaves': 4, 'min_child_samples': 63, 'learning_rate': 0.15792100857904337, 'log_max_bin': 6, 'colsample_bytree': 0.8675801587327742, 'reg_alpha': 0.029113164866915998, 'reg_lambda': 1.1389580224305669}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 66, 'num_leaves': 4, 'min_child_samples': 63, 'learning_rate': 0.15792100857904337, 'log_max_bin': 6, 'colsample_bytree': 0.8675801587327742, 'reg_alpha': 0.029113164866915998, 'reg_lambda': 1.1389580224305669}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 162, 'num_leaves': 4, 'min_child_samples': 81, 'learning_rate': 0.2983745472848827, 'log_max_bin': 6, 'colsample_bytree': 0.8695837765611358, 'reg_alpha': 0.129896241454976, 'reg_lambda': 15.603722661471139}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 162, 'num_leaves': 4, 'min_child_samples': 81, 'learning_rate': 0.2983745472848827, 'log_max_bin': 6, 'colsample_bytree': 0.8695837765611358, 'reg_alpha': 0.129896241454976, 'reg_lambda': 15.603722661471139}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 244, 'num_leaves': 4, 'min_child_samples': 66, 'learning_rate': 0.09384952888449109, 'log_max_bin': 6, 'colsample_bytree': 0.9991377697705415, 'reg_alpha': 1.0176418043593494, 'reg_lambda': 11.735517914858072}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 244, 'num_leaves': 4, 'min_child_samples': 66, 'learning_rate': 0.09384952888449109, 'log_max_bin': 6, 'colsample_bytree': 0.9991377697705415, 'reg_alpha': 1.0176418043593494, 'reg_lambda': 11.735517914858072}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 353, 'num_leaves': 6, 'min_child_samples': 74, 'learning_rate': 0.07409100261325174, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.3502883007396542, 'reg_lambda': 16.567615417370998}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 353, 'num_leaves': 6, 'min_child_samples': 74, 'learning_rate': 0.07409100261325174, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 0.3502883007396542, 'reg_lambda': 16.567615417370998}}\n",
            "{'Current Learner': 'lgbm', 'Current Sample': 2197, 'Current Hyper-parameters': {'n_estimators': 886, 'num_leaves': 5, 'min_child_samples': 65, 'learning_rate': 0.07144064602964592, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 1.8860629883494746, 'reg_lambda': 5.008993431666809}, 'Best Learner': 'lgbm', 'Best Hyper-parameters': {'n_estimators': 886, 'num_leaves': 5, 'min_child_samples': 65, 'learning_rate': 0.07144064602964592, 'log_max_bin': 7, 'colsample_bytree': 1.0, 'reg_alpha': 1.8860629883494746, 'reg_lambda': 5.008993431666809}}\n"
          ]
        }
      ],
      "source": [
        "from flaml.data import get_output_from_log\n",
        "time_history, best_valid_loss_history, valid_loss_history, config_history, metric_history = \\\n",
        "    get_output_from_log(filename=settings['log_file_name'], time_budget=240)\n",
        "for config in config_history:\n",
        "    print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a08a6fc1",
      "metadata": {
        "id": "a08a6fc1",
        "outputId": "52af8c29-6802-4252-e461-d38bf5c11ac3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.title('Learning Curve')\n",
        "plt.xlabel('Wall Clock Time (s)')\n",
        "plt.ylabel('Validation Accuracy')\n",
        "plt.scatter(time_history, 1 - np.array(valid_loss_history))\n",
        "plt.step(time_history, 1 - np.array(best_valid_loss_history), where='post')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "84ea470d",
      "metadata": {
        "id": "84ea470d"
      },
      "outputs": [],
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "lgbm = LGBMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "4d88c8bc",
      "metadata": {
        "id": "4d88c8bc"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder = label_encoder.fit(y_train)\n",
        "Y_train = label_encoder.transform(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "cffc2ad2",
      "metadata": {
        "id": "cffc2ad2",
        "outputId": "233b1123-97a1-4340-ed29-473533bc886e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "lgbm.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ace93d3c",
      "metadata": {
        "id": "ace93d3c"
      },
      "outputs": [],
      "source": [
        "y_pred_lgbm = lgbm.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "db4e9c3b",
      "metadata": {
        "id": "db4e9c3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa8f03d-a4b2-4465-df1b-e9a261fadbfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default lgbm accuracy = -2.396349102536697\n",
            "flaml (5 min) r2 = 0.8851201052892462\n",
            "r2 = 0.8851201052892462\n",
            "mse = 748746104.4039737\n",
            "mae = 15136.546803986184\n"
          ]
        }
      ],
      "source": [
        "#print('default xgboost accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred_xgb, Y_test))\n",
        "print('default lgbm accuracy', '=', 1 - sklearn_metric_loss_score('r2', y_pred_lgbm, Y_test))\n",
        "#print('default catboost accuracy', '=', 1 - sklearn_metric_loss_score('accuracy', y_pred_cat, Y_test))\n",
        "print('flaml (5 min) r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('r2', '=', 1 - sklearn_metric_loss_score('r2', y_pred, y_test))\n",
        "print('mse', '=', sklearn_metric_loss_score('mse', y_pred, y_test))\n",
        "print('mae', '=', sklearn_metric_loss_score('mae', y_pred, y_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}